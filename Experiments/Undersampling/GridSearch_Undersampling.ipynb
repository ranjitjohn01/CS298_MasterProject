{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zH6Vc-v21GbH",
        "D-g3oW1x0fl2",
        "OJ9e_0k21Mfl",
        "4M4Ratgk1PJm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svenr4xYNIy_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.under_sampling import TomekLinks, OneSidedSelection,EditedNearestNeighbours\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import make_scorer, f1_score"
      ],
      "metadata": {
        "id": "jnF46btkNm-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data (Category)"
      ],
      "metadata": {
        "id": "zH6Vc-v21GbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('/content/drive/MyDrive/Datasets/VirusShare_Opcodes/csvFiles/DATASET_SHUFFLED_VirusShare_proportions_and_targets.csv')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/VirusShare_Opcodes/csvFiles/MalwareCategory_DATASET_Increased_Imbalance.csv')\n",
        "\n",
        "# Delete rows where 'Category' is equal to 'Unknown'\n",
        "df = df[(df['Category'] != 'Unknown')]\n",
        "df['Category'].value_counts()"
      ],
      "metadata": {
        "id": "897K7LesNsXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data (Family)"
      ],
      "metadata": {
        "id": "D-g3oW1x0fl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('/content/drive/MyDrive/Datasets/VirusShare_Opcodes/csvFiles/DATASET_SHUFFLED_VirusShare_proportions_and_targets.csv')\\\n",
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/VirusShare_Opcodes/csvFiles/MalwareFamily_DATASET_FINAL_Increased_Imbalance.csv')\n",
        "# Delete rows where 'name' is equal to 'Unknown_Family'\n",
        "df = df[(df['name'] != 'Unknown_Family')]\n",
        "df['name'].value_counts()"
      ],
      "metadata": {
        "id": "8_CNyFAVWwGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features/Targets"
      ],
      "metadata": {
        "id": "OJ9e_0k21Mfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the features\n",
        "features = df.drop(columns=[\"file_name\",\"name\", \"Category\",\"Category Target\", \"Family Target\"]).astype(float)\n",
        "\n",
        "# Prepare the target\n",
        "targets = df[\"Category Target\"].astype(int)\n",
        "\n",
        "# # Prepare the target\n",
        "# targets = df[\"Family Target\"].astype(int)"
      ],
      "metadata": {
        "id": "3l_P0TE-OvmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Test Split"
      ],
      "metadata": {
        "id": "4M4Ratgk1PJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features,\n",
        "    targets,\n",
        "    stratify=targets,\n",
        "    test_size=0.2,\n",
        "    random_state=0)\n",
        "\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "gbChHFUIPL50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GridSearchCV"
      ],
      "metadata": {
        "id": "z4jIZ5mrXPLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=0),\n",
        "    'MLP': MLPClassifier(hidden_layer_sizes=(200,200, 200),early_stopping=True,random_state=0, n_iter_no_change= 5),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'SVM': SVC(kernel='rbf', random_state=0,class_weight= None, gamma= 'scale')\n",
        "}"
      ],
      "metadata": {
        "id": "fo828YOgb6QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. TomekLinks"
      ],
      "metadata": {
        "id": "O1opTkYWdq-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the TomekLinks undersampler\n",
        "tomek_links = TomekLinks()\n",
        "\n",
        "# List to hold all grid search results\n",
        "results = []\n",
        "\n",
        "# Create a custom scorer that uses the macro average\n",
        "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# Test each classifier with TomekLinks\n",
        "for name, clf in classifiers.items():\n",
        "    print(f\"Testing {name} with TomekLinks\")\n",
        "\n",
        "    # Define the pipeline with make_pipeline from imblearn\n",
        "    pipeline = make_pipeline(tomek_links, clf)\n",
        "\n",
        "    # Set the parameter grid for the sampling_strategy in TomekLinks\n",
        "    param_grid = {\n",
        "        'tomeklinks__sampling_strategy': ['auto', 'majority']\n",
        "    }\n",
        "\n",
        "    # Set up GridSearchCV\n",
        "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring=f1_macro_scorer, verbose=1)\n",
        "\n",
        "    # Fit GridSearchCV\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Store the best estimator, its parameters, and the corresponding score\n",
        "    results.append({\n",
        "        'Classifier': name,\n",
        "        'Best_Params': grid_search.best_params_,\n",
        "        'Best_Score': grid_search.best_score_\n",
        "    })\n",
        "\n",
        "# Output the results\n",
        "for result in results:\n",
        "    print(f\"Classifier: {result['Classifier']}, Best Score: {result['Best_Score']}, Params: {result['Best_Params']}\")\n"
      ],
      "metadata": {
        "id": "455somTyd59p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. EdittedNearestNeighbors"
      ],
      "metadata": {
        "id": "F8XO77-ndtK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ENN undersampler\n",
        "enn = EditedNearestNeighbours()\n",
        "\n",
        "# List to hold all grid search results\n",
        "results = []\n",
        "\n",
        "# Create a custom scorer that uses the macro average\n",
        "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# Test each classifier with ENN\n",
        "for name, clf in classifiers.items():\n",
        "    print(f\"Testing {name} with ENN\")\n",
        "\n",
        "    # Define the pipeline with make_pipeline from imblearn\n",
        "    pipeline = make_pipeline(enn, clf)\n",
        "\n",
        "    # Set the parameter grid for the sampling_strategy and n_neighbors in ENN\n",
        "    param_grid = {\n",
        "        'editednearestneighbours__sampling_strategy': ['auto', 'majority'],\n",
        "        'editednearestneighbours__n_neighbors': list(range(1, 11))\n",
        "    }\n",
        "\n",
        "    # Set up GridSearchCV\n",
        "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring=f1_macro_scorer, verbose=1)\n",
        "\n",
        "    # Fit GridSearchCV\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Store the best estimator, its parameters, and the corresponding score\n",
        "    results.append({\n",
        "        'Classifier': name,\n",
        "        'Best_Params': grid_search.best_params_,\n",
        "        'Best_Score': grid_search.best_score_\n",
        "    })\n",
        "\n",
        "# Output the results\n",
        "for result in results:\n",
        "    print(f\"Classifier: {result['Classifier']}, Best Score: {result['Best_Score']}, Params: {result['Best_Params']}\")\n"
      ],
      "metadata": {
        "id": "H-_HRftpeieh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. OneSidedSelection"
      ],
      "metadata": {
        "id": "2KjWZYbldxbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the OSS undersampler\n",
        "oss = OneSidedSelection(random_state=0)\n",
        "\n",
        "# List to hold all grid search results\n",
        "results = []\n",
        "\n",
        "# Create a custom scorer that uses the macro average\n",
        "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# Test each classifier with OSS\n",
        "for name, clf in classifiers.items():\n",
        "    print(f\"Testing {name} with OSS\")\n",
        "\n",
        "    # Define the pipeline with make_pipeline from imblearn\n",
        "    pipeline = make_pipeline(oss, clf)\n",
        "\n",
        "    # Set the parameter grid for n_neighbors in OSS\n",
        "    param_grid = {\n",
        "        'onesidedselection__n_neighbors': list(range(1, 11))  # Test n_neighbors from 1 to 10\n",
        "    }\n",
        "\n",
        "    # Set up GridSearchCV\n",
        "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring=f1_macro_scorer, verbose=1)\n",
        "\n",
        "    # Fit GridSearchCV\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Store the best estimator, its parameters, and the corresponding score\n",
        "    results.append({\n",
        "        'Classifier': name,\n",
        "        'Best_Params': grid_search.best_params_,\n",
        "        'Best_Score': grid_search.best_score_\n",
        "    })\n",
        "\n",
        "# Output the results\n",
        "for result in results:\n",
        "    print(f\"Classifier: {result['Classifier']}, Best Score: {result['Best_Score']}, Params: {result['Best_Params']}\")"
      ],
      "metadata": {
        "id": "qYMnGu6cfFSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}