{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["zH6Vc-v21GbH","D-g3oW1x0fl2","OJ9e_0k21Mfl","4M4Ratgk1PJm"],"authorship_tag":"ABX9TyPMESpN28VenxnVs+gWB8Sd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"svenr4xYNIy_"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report\n","from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n","from imblearn.pipeline import make_pipeline\n","from sklearn.metrics import make_scorer, f1_score"],"metadata":{"id":"jnF46btkNm-N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Data (Category)"],"metadata":{"id":"zH6Vc-v21GbH"}},{"cell_type":"code","source":["# df = pd.read_csv('/content/drive/MyDrive/Datasets/VirusShare_Opcodes/csvFiles/DATASET_SHUFFLED_VirusShare_proportions_and_targets.csv')\n","df = pd.read_csv('/content/drive/MyDrive/Datasets/VirusShare_Opcodes/csvFiles/MalwareCategory_DATASET_Increased_Imbalance.csv')\n","\n","# Delete rows where 'Category' is equal to 'Unknown'\n","df = df[(df['Category'] != 'Unknown')]\n","df['Category'].value_counts()"],"metadata":{"id":"897K7LesNsXk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Data (Family)"],"metadata":{"id":"D-g3oW1x0fl2"}},{"cell_type":"code","source":["# df = pd.read_csv('/content/drive/MyDrive/Datasets/VirusShare_Opcodes/csvFiles/DATASET_SHUFFLED_VirusShare_proportions_and_targets.csv')\\\n","df = pd.read_csv('/content/drive/MyDrive/Datasets/VirusShare_Opcodes/csvFiles/MalwareFamily_DATASET_FINAL_Increased_Imbalance.csv')\n","# Delete rows where 'name' is equal to 'Unknown_Family'\n","df = df[(df['name'] != 'Unknown_Family')]\n","df['name'].value_counts()"],"metadata":{"id":"8_CNyFAVWwGT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Features/Targets"],"metadata":{"id":"OJ9e_0k21Mfl"}},{"cell_type":"code","source":["# Prepare the features\n","features = df.drop(columns=[\"file_name\",\"name\", \"Category\",\"Category Target\", \"Family Target\"]).astype(float)\n","\n","# Prepare the target\n","targets = df[\"Category Target\"].astype(int)\n","\n","# # Prepare the target\n","# targets = df[\"Family Target\"].astype(int)"],"metadata":{"id":"3l_P0TE-OvmF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train/Test Split"],"metadata":{"id":"4M4Ratgk1PJm"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(\n","    features,\n","    targets,\n","    stratify=targets,\n","    test_size=0.2,\n","    random_state=0)\n","\n","\n","X_train.shape, X_test.shape"],"metadata":{"id":"gbChHFUIPL50"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GridSearchCV"],"metadata":{"id":"z4jIZ5mrXPLG"}},{"cell_type":"code","source":["# Define the classifiers\n","classifiers = {\n","    'Random Forest': RandomForestClassifier(random_state=0),\n","    'MLP': MLPClassifier(hidden_layer_sizes=(200,200, 200),early_stopping=True,random_state=0, n_iter_no_change= 5),\n","    'KNN': KNeighborsClassifier(n_neighbors=5),\n","    'SVM': SVC(kernel='rbf', random_state=0,class_weight= None, gamma= 'scale')\n","}"],"metadata":{"id":"fo828YOgb6QI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. SMOTE"],"metadata":{"id":"UhzsTlVBbqQA"}},{"cell_type":"code","source":["# Define the SMOTE oversampler\n","smote = SMOTE(random_state=0)\n","\n","# List to hold all grid search results\n","results = []\n","\n","# Create a custom scorer that uses the macro average which is generally a good default for multiclass problems\n","f1_macro_scorer = make_scorer(f1_score, average='macro')\n","\n","# Test each classifier with SMOTE\n","for name, clf in classifiers.items():\n","    print(f\"Testing {name} with SMOTE\")\n","\n","    # Define the pipeline with make_pipeline from imblearn\n","    pipeline = make_pipeline(smote, clf)\n","\n","    # Set the parameter grid for k_neighbors in SMOTE\n","    param_grid = {\n","        'smote__k_neighbors': list(range(1, 21))  # Corrected parameter prefix\n","    }\n","\n","    # Set up GridSearchCV\n","    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring=f1_macro_scorer, verbose=1)\n","\n","    # Fit GridSearchCV\n","    grid_search.fit(X_train, y_train)\n","\n","    # Store the best estimator, its parameters, and the corresponding score\n","    results.append({\n","        'Classifier': name,\n","        'Best_Params': grid_search.best_params_,\n","        'Best_Score': grid_search.best_score_\n","    })\n","\n","# Output the results\n","for result in results:\n","    print(f\"Classifier: {result['Classifier']}, Best Score: {result['Best_Score']}, Params: {result['Best_Params']}\")\n"],"metadata":{"id":"IJagefHJXMGW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. ADASYN"],"metadata":{"id":"fvNHxuH8bugv"}},{"cell_type":"code","source":["# Define the ADASYN oversampler\n","adasyn = ADASYN(random_state=0)\n","\n","# List to hold all grid search results\n","results = []\n","\n","# Create a custom scorer that uses the macro average\n","f1_macro_scorer = make_scorer(f1_score, average='macro')\n","\n","# Test each classifier with ADASYN\n","for name, clf in classifiers.items():\n","    print(f\"Testing {name} with ADASYN\")\n","\n","    # Define the pipeline with make_pipeline from imblearn\n","    pipeline = make_pipeline(adasyn, clf)\n","\n","    # Set the parameter grid for k_neighbors in ADASYN\n","    param_grid = {\n","        'adasyn__n_neighbors': list(range(1, 21))  # Corrected parameter prefix\n","    }\n","\n","    # Set up GridSearchCV\n","    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring=f1_macro_scorer, verbose=1)\n","\n","    # Fit GridSearchCV\n","    grid_search.fit(X_train, y_train)\n","\n","    # Store the best estimator, its parameters, and the corresponding score\n","    results.append({\n","        'Classifier': name,\n","        'Best_Params': grid_search.best_params_,\n","        'Best_Score': grid_search.best_score_\n","    })\n","\n","# Output the results\n","for result in results:\n","    print(f\"Classifier: {result['Classifier']}, Best Score: {result['Best_Score']}, Params: {result['Best_Params']}\")"],"metadata":{"id":"_glbXMgnbx5b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. BorderlineSMOTE"],"metadata":{"id":"9dlclWfzcpkD"}},{"cell_type":"code","source":["# Define the BorderlineSMOTE oversampler\n","borderline_smote = BorderlineSMOTE(random_state=0)\n","\n","# List to hold all grid search results\n","results = []\n","\n","# Create a custom scorer that uses the macro average\n","f1_macro_scorer = make_scorer(f1_score, average='macro')\n","\n","# Test each classifier with BorderlineSMOTE\n","for name, clf in classifiers.items():\n","    print(f\"Testing {name} with BorderlineSMOTE\")\n","\n","    # Define the pipeline with make_pipeline from imblearn\n","    pipeline = make_pipeline(borderline_smote, clf)\n","\n","    # Set the parameter grid for k_neighbors and m_neighbors in BorderlineSMOTE\n","    param_grid = {\n","        'borderlinesmote__k_neighbors': list(range(1, 21)),\n","        'borderlinesmote__m_neighbors': list(range(1, 21))\n","    }\n","\n","    # Set up GridSearchCV\n","    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring=f1_macro_scorer, verbose=1)\n","\n","    # Fit GridSearchCV\n","    grid_search.fit(X_train, y_train)\n","\n","    # Store the best estimator, its parameters, and the corresponding score\n","    results.append({\n","        'Classifier': name,\n","        'Best_Params': grid_search.best_params_,\n","        'Best_Score': grid_search.best_score_\n","    })\n","\n","# Output the results\n","for result in results:\n","    print(f\"Classifier: {result['Classifier']}, Best Score: {result['Best_Score']}, Params: {result['Best_Params']}\")\n"],"metadata":{"id":"fjeX86s-cjx4"},"execution_count":null,"outputs":[]}]}